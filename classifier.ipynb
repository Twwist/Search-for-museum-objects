{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7ZCBWfXGLlH",
        "outputId": "31f70ed4-2a4c-4fbf-e5c2-63353f7fb4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCw3iZG_FXFJ",
        "outputId": "88cafd41-3da4-4691-8d74-1515fc1988ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.16)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.29.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install timm\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ofAH5-FVFLvD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import gc\n",
        "import platform\n",
        "import random\n",
        "import matplotlib.pyplot as plt #графики\n",
        "import plotly.express as px #графики\n",
        "import seaborn as sns #графики\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd #пандас для загрузки датасета\n",
        "from tqdm import tqdm # красивое отображение циклов\n",
        "\n",
        "import torch #пайторч\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "from datasets import Dataset # датасет для хаггингфейс\n",
        "import pandas as pd\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoModel, BeitForImageClassification # нужно, чтобы качать модели с hf\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, f1_score # рассчитывать метрики\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import evaluate  # рассчитывать метрики\n",
        "\n",
        "import timm # библиотека с нужными моделями\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "import glob\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import albumentations as A # аугментации\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm.contrib import tzip\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JLEdZRW0GWI-",
        "outputId": "1e8c4024-f9f5-45cf-d2dc-efafd023f9f3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>object_id</th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>group</th>\n",
              "      <th>img_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10669820</td>\n",
              "      <td>Водолей - коник (фрагмент - голова)</td>\n",
              "      <td>сероглиняный, лепной, со сплошным белым ангобо...</td>\n",
              "      <td>Археология</td>\n",
              "      <td>7862029.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4489444</td>\n",
              "      <td>Винтовка «Самозарядная винтовка Токарева» (мет...</td>\n",
              "      <td>На стволе имеется надульник, на  торце которог...</td>\n",
              "      <td>Оружие</td>\n",
              "      <td>9461061.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8722586</td>\n",
              "      <td>Инструмент. Калибр-скоба</td>\n",
              "      <td>Прямоугольная пластина с усечёнными углами и д...</td>\n",
              "      <td>Прочие</td>\n",
              "      <td>5095122.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3712248</td>\n",
              "      <td>Судомодель. НИС \"Космонавт  Виктор Пацаев\".</td>\n",
              "      <td>Корпус модели, надстройки, шлюпки выполнены и...</td>\n",
              "      <td>Прочие</td>\n",
              "      <td>551422.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6339754</td>\n",
              "      <td>Сабля.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Оружие</td>\n",
              "      <td>2592073.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20340</th>\n",
              "      <td>19945381</td>\n",
              "      <td>La Sainte Bible avec des explications &amp; reflex...</td>\n",
              "      <td>В переплете коричневой  кожи, на корешке три н...</td>\n",
              "      <td>Редкие книги</td>\n",
              "      <td>20653985.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20341</th>\n",
              "      <td>10334174</td>\n",
              "      <td>Фрагмент ручки синопской амфоры с сохранившимс...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Археология</td>\n",
              "      <td>41217662.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20342</th>\n",
              "      <td>4708600</td>\n",
              "      <td>Шашка кавказская.(ножны)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Оружие</td>\n",
              "      <td>1766049.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20343</th>\n",
              "      <td>9622688</td>\n",
              "      <td>Висмутин</td>\n",
              "      <td>Висмутин. Зёрна в кварце</td>\n",
              "      <td>Минералогия</td>\n",
              "      <td>6305416.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20344</th>\n",
              "      <td>46780517</td>\n",
              "      <td>Чешуйка</td>\n",
              "      <td>кремневая, серо-голубого цвета.</td>\n",
              "      <td>Археология</td>\n",
              "      <td>57812894.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20345 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       object_id                                               name  \\\n",
              "0       10669820                Водолей - коник (фрагмент - голова)   \n",
              "1        4489444  Винтовка «Самозарядная винтовка Токарева» (мет...   \n",
              "2        8722586                           Инструмент. Калибр-скоба   \n",
              "3        3712248        Судомодель. НИС \"Космонавт  Виктор Пацаев\".   \n",
              "4        6339754                                             Сабля.   \n",
              "...          ...                                                ...   \n",
              "20340   19945381  La Sainte Bible avec des explications & reflex...   \n",
              "20341   10334174  Фрагмент ручки синопской амфоры с сохранившимс...   \n",
              "20342    4708600                           Шашка кавказская.(ножны)   \n",
              "20343    9622688                                           Висмутин   \n",
              "20344   46780517                                            Чешуйка   \n",
              "\n",
              "                                             description         group  \\\n",
              "0      сероглиняный, лепной, со сплошным белым ангобо...    Археология   \n",
              "1      На стволе имеется надульник, на  торце которог...        Оружие   \n",
              "2      Прямоугольная пластина с усечёнными углами и д...        Прочие   \n",
              "3       Корпус модели, надстройки, шлюпки выполнены и...        Прочие   \n",
              "4                                                    NaN        Оружие   \n",
              "...                                                  ...           ...   \n",
              "20340  В переплете коричневой  кожи, на корешке три н...  Редкие книги   \n",
              "20341                                                NaN    Археология   \n",
              "20342                                                NaN        Оружие   \n",
              "20343                           Висмутин. Зёрна в кварце   Минералогия   \n",
              "20344                    кремневая, серо-голубого цвета.    Археология   \n",
              "\n",
              "           img_name  \n",
              "0       7862029.jpg  \n",
              "1       9461061.jpg  \n",
              "2       5095122.jpg  \n",
              "3        551422.jpg  \n",
              "4       2592073.jpg  \n",
              "...             ...  \n",
              "20340  20653985.jpg  \n",
              "20341  41217662.jpg  \n",
              "20342   1766049.jpg  \n",
              "20343   6305416.jpg  \n",
              "20344  57812894.jpg  \n",
              "\n",
              "[20345 rows x 5 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('train.csv', sep=';')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncomEFb1FLvG",
        "outputId": "0f74c0dd-d9ec-40da-e84d-ffcfde83cc5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Археология', 'Оружие', 'Прочие', 'Нумизматика', 'Фото, негативы',\n",
              "       'Редкие книги', 'Документы', 'Печатная продукция', 'ДПИ',\n",
              "       'Скульптура', 'Графика', 'Техника', 'Живопись',\n",
              "       'Естественнонауч.коллекция', 'Минералогия'], dtype=object)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "name_class = df['group'].unique()\n",
        "name_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eeWWBjA1FLvH",
        "outputId": "768a1a49-0997-4f1b-89b6-4fdbd909d018"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>cls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/10669820/7862029.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/4489444/9461061.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/8722586/5095122.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train/3712248/551422.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train/6339754/2592073.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20340</th>\n",
              "      <td>train/19945381/20653985.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20341</th>\n",
              "      <td>train/10334174/41217662.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20342</th>\n",
              "      <td>train/4708600/1766049.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20343</th>\n",
              "      <td>train/9622688/6305416.jpg</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20344</th>\n",
              "      <td>train/46780517/57812894.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20345 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               img  cls\n",
              "0       train/10669820/7862029.jpg    0\n",
              "1        train/4489444/9461061.jpg    1\n",
              "2        train/8722586/5095122.jpg    2\n",
              "3         train/3712248/551422.jpg    2\n",
              "4        train/6339754/2592073.jpg    1\n",
              "...                            ...  ...\n",
              "20340  train/19945381/20653985.jpg    5\n",
              "20341  train/10334174/41217662.jpg    0\n",
              "20342    train/4708600/1766049.jpg    1\n",
              "20343    train/9622688/6305416.jpg   14\n",
              "20344  train/46780517/57812894.jpg    0\n",
              "\n",
              "[20345 rows x 2 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_path = 'train'\n",
        "\n",
        "sdict = {name: id for name, id in zip(name_class, range(len(name_class)))}\n",
        "\n",
        "images = [main_path + '/' + str(object_id) + '/' + str(img_name) for object_id, img_name in zip(df['object_id'], df['img_name'])]\n",
        "classes = [sdict[i] for i in df['group']]\n",
        "\n",
        "df = pd.DataFrame(data={\n",
        "    'img': images,\n",
        "    'cls': classes\n",
        "})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Археология': 0,\n",
              " 'Оружие': 1,\n",
              " 'Прочие': 2,\n",
              " 'Нумизматика': 3,\n",
              " 'Фото, негативы': 4,\n",
              " 'Редкие книги': 5,\n",
              " 'Документы': 6,\n",
              " 'Печатная продукция': 7,\n",
              " 'ДПИ': 8,\n",
              " 'Скульптура': 9,\n",
              " 'Графика': 10,\n",
              " 'Техника': 11,\n",
              " 'Живопись': 12,\n",
              " 'Естественнонауч.коллекция': 13,\n",
              " 'Минералогия': 14}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "somIR1Q0FLvH",
        "outputId": "e6a0a627-9227-4a34-cff6-60271a5e02fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='cls', ylabel='Count'>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.histplot(data=df, x=\"cls\", bins=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "98d7447ecbb140639f339d6f6fa3bb06",
            "ab69d4930c24461ab6d52edb6fd4da4c",
            "26a7b185e2384803b29871db20f894b9",
            "5eed4f05915c49539c6c8aa3510436f4",
            "619e5ec37fd040ff808d37bdc58abe9e",
            "cae586cb2e594ee59f495d0201fbee33",
            "28e1f2a4ca0e45e7b8819e88ca7d69ae",
            "9e293b426a0940fb9c33b33ba2d08e40",
            "c695e677533d4f48a77c1117afa7ecc6",
            "a1ee614194194f39ad8c94fe711a139a",
            "c248d5dbcc944693a3b5f9dcf5ab06c6",
            "da7f103ed4cd49d6a2f7ea884e3a098f",
            "77024ec0fa7d4078afe6a3f1498c480c",
            "fdd0f271705844f9bef09e6fcf27e0ab",
            "f1bf1dbce5e94a6e86133141241a2669",
            "8cc5e38c61034393ad64e0bb8cd828e5",
            "8a05434793314355930f19a6a394c7b3",
            "85b8869fde344cfbb77418ee6168e981",
            "6f735b9a721d4e2a93ea9fa342ccb83d",
            "19cdf0616e0f49a0949027f05eebc3de",
            "08549656f83e45e288ab91431e279f1e",
            "af63a2bdeadb406889a9a3f898e33eef"
          ]
        },
        "id": "e34900zpFLvI",
        "outputId": "56cd6720-8d7b-4aec-8da7-ef9e30a59c35"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e20b1f099c334c5c9fa5f726d350a55e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Stringifying the column:   0%|          | 0/20345 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa2e34cd97774d4a809f9b9069606988",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting to class labels:   0%|          | 0/20345 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['img', 'cls'],\n",
              "        num_rows: 18310\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['img', 'cls'],\n",
              "        num_rows: 2035\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = Dataset.from_pandas(df)\n",
        "ds = ds.class_encode_column(\"cls\")\n",
        "ds = ds.train_test_split(test_size=0.1, seed=42, shuffle=True, stratify_by_column='cls')\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au__AWkfFLvI",
        "outputId": "ab6d7d41-4f86-48ce-fe05-d369ea1369b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
            "Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-base-patch4-window12-192-22k and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([15, 1024]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([15]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Swinv2ForImageClassification(\n",
              "  (swinv2): Swinv2Model(\n",
              "    (embeddings): Swinv2Embeddings(\n",
              "      (patch_embeddings): Swinv2PatchEmbeddings(\n",
              "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): Swinv2Encoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): Swinv2Stage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x Swinv2Layer(\n",
              "              (attention): Swinv2Attention(\n",
              "                (self): Swinv2SelfAttention(\n",
              "                  (continuous_position_bias_mlp): Sequential(\n",
              "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "                    (1): ReLU(inplace=True)\n",
              "                    (2): Linear(in_features=512, out_features=4, bias=False)\n",
              "                  )\n",
              "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (key): Linear(in_features=128, out_features=128, bias=False)\n",
              "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): Swinv2SelfOutput(\n",
              "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (drop_path): Swinv2DropPath(p=0.1)\n",
              "              (intermediate): Swinv2Intermediate(\n",
              "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): Swinv2Output(\n",
              "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "          (downsample): Swinv2PatchMerging(\n",
              "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Swinv2Stage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x Swinv2Layer(\n",
              "              (attention): Swinv2Attention(\n",
              "                (self): Swinv2SelfAttention(\n",
              "                  (continuous_position_bias_mlp): Sequential(\n",
              "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "                    (1): ReLU(inplace=True)\n",
              "                    (2): Linear(in_features=512, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (key): Linear(in_features=256, out_features=256, bias=False)\n",
              "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): Swinv2SelfOutput(\n",
              "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (drop_path): Swinv2DropPath(p=0.1)\n",
              "              (intermediate): Swinv2Intermediate(\n",
              "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): Swinv2Output(\n",
              "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "          (downsample): Swinv2PatchMerging(\n",
              "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): Swinv2Stage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-17): 18 x Swinv2Layer(\n",
              "              (attention): Swinv2Attention(\n",
              "                (self): Swinv2SelfAttention(\n",
              "                  (continuous_position_bias_mlp): Sequential(\n",
              "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "                    (1): ReLU(inplace=True)\n",
              "                    (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=False)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): Swinv2SelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (drop_path): Swinv2DropPath(p=0.1)\n",
              "              (intermediate): Swinv2Intermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): Swinv2Output(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "          (downsample): Swinv2PatchMerging(\n",
              "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Swinv2Stage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x Swinv2Layer(\n",
              "              (attention): Swinv2Attention(\n",
              "                (self): Swinv2SelfAttention(\n",
              "                  (continuous_position_bias_mlp): Sequential(\n",
              "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "                    (1): ReLU(inplace=True)\n",
              "                    (2): Linear(in_features=512, out_features=32, bias=False)\n",
              "                  )\n",
              "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): Swinv2SelfOutput(\n",
              "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (drop_path): Swinv2DropPath(p=0.1)\n",
              "              (intermediate): Swinv2Intermediate(\n",
              "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): Swinv2Output(\n",
              "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=15, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-base-patch4-window12-192-22k\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"microsoft/swinv2-base-patch4-window12-192-22k\", num_labels=15, ignore_mismatched_sizes=True)\n",
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "for param in model.swinv2.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gNV2A3KaFLvI"
      },
      "outputs": [],
      "source": [
        "def auto_transforms(examples):\n",
        "    images = [Image.open(path).convert(\"RGB\") for path in examples[\"img\"]]\n",
        "    inputs = preprocessor(images=images, return_tensors=\"pt\")\n",
        "    inputs['labels'] = torch.tensor(examples['cls'])\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LJqUzD-hFLvI"
      },
      "outputs": [],
      "source": [
        "ds = ds.with_transform(auto_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pRkgGFgiFLvJ"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Qeu6RICmFLvJ"
      },
      "outputs": [],
      "source": [
        "f1 = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return f1.compute(predictions=predictions, references=labels)\n",
        "\n",
        "def custom_rmse(act, pred): # функция\n",
        "    diff = pred - act # находим разницу между прогнозируемыми и наблюдаемыми значениями\n",
        "    differences_squared = diff ** 2 # возводим в квадрат (чтобы избавиться от отрицательных значений)\n",
        "    mean_diff = np.sqrt(differences_squared.mean()) # находим среднее значение\n",
        "\n",
        "    return mean_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "0bpwYjyJFLvJ",
        "outputId": "fc5d2cd3-19b2-441b-92fe-eba981d0cfcd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "361b45e60a8f4817bcc0bf7a92281ea3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/288 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.5055, 'grad_norm': 3.6458640098571777, 'learning_rate': 0.0004826388888888889, 'epoch': 0.07}\n",
            "{'loss': 1.8047, 'grad_norm': 3.4575963020324707, 'learning_rate': 0.0004652777777777778, 'epoch': 0.14}\n",
            "{'loss': 1.4141, 'grad_norm': 2.807126998901367, 'learning_rate': 0.0004479166666666667, 'epoch': 0.21}\n",
            "{'loss': 1.1842, 'grad_norm': 2.48751163482666, 'learning_rate': 0.0004305555555555556, 'epoch': 0.28}\n",
            "{'loss': 1.0417, 'grad_norm': 2.4209983348846436, 'learning_rate': 0.00041319444444444444, 'epoch': 0.35}\n",
            "{'loss': 1.0097, 'grad_norm': 2.6187310218811035, 'learning_rate': 0.0003958333333333333, 'epoch': 0.42}\n",
            "{'loss': 0.9044, 'grad_norm': 2.355313539505005, 'learning_rate': 0.0003784722222222222, 'epoch': 0.49}\n",
            "{'loss': 0.9694, 'grad_norm': 2.910196542739868, 'learning_rate': 0.0003611111111111111, 'epoch': 0.56}\n",
            "{'loss': 0.9035, 'grad_norm': 2.4179348945617676, 'learning_rate': 0.00034375, 'epoch': 0.62}\n",
            "{'loss': 0.9199, 'grad_norm': 2.1832337379455566, 'learning_rate': 0.0003263888888888889, 'epoch': 0.69}\n",
            "{'loss': 0.8757, 'grad_norm': 2.2041873931884766, 'learning_rate': 0.0003090277777777778, 'epoch': 0.76}\n",
            "{'loss': 0.8003, 'grad_norm': 2.0316219329833984, 'learning_rate': 0.0002916666666666667, 'epoch': 0.83}\n",
            "{'loss': 0.8436, 'grad_norm': 2.110521078109741, 'learning_rate': 0.0002743055555555556, 'epoch': 0.9}\n",
            "{'loss': 0.7701, 'grad_norm': 2.0105230808258057, 'learning_rate': 0.0002569444444444444, 'epoch': 0.97}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9986270ee024263af64efb802a7a2e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7468463778495789, 'eval_accuracy': 0.772972972972973, 'eval_runtime': 58.7166, 'eval_samples_per_second': 34.658, 'eval_steps_per_second': 0.272, 'epoch': 1.0}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[38], line 38\u001b[0m\n\u001b[1;32m      9\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     10\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     remove_unused_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     29\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     30\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/transformers/trainer.py:2085\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2084\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2085\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2086\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2088\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/accelerate/data_loader.py:462\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 462\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/datasets/arrow_dataset.py:2814\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2814\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2815\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/datasets/arrow_dataset.py:2810\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/datasets/arrow_dataset.py:2795\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2794\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2795\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2797\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/datasets/formatting/formatting.py:629\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    627\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/datasets/formatting/formatting.py:400\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/datasets/formatting/formatting.py:515\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    513\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m    514\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[34], line 3\u001b[0m, in \u001b[0;36mauto_transforms\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_transforms\u001b[39m(examples):\n\u001b[1;32m      2\u001b[0m     images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mopen(path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m----> 3\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/transformers/image_processing_utils.py:551\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/transformers/models/vit/image_processing_vit.py:267\u001b[0m, in \u001b[0;36mViTImageProcessor.preprocess\u001b[0;34m(self, images, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, return_tensors, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     input_data_format \u001b[38;5;241m=\u001b[39m infer_channel_dimension_format(images[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_resize:\n\u001b[0;32m--> 267\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize(image\u001b[38;5;241m=\u001b[39mimage, size\u001b[38;5;241m=\u001b[39msize_dict, resample\u001b[38;5;241m=\u001b[39mresample, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format)\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    270\u001b[0m     ]\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_rescale:\n\u001b[1;32m    273\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale(image\u001b[38;5;241m=\u001b[39mimage, scale\u001b[38;5;241m=\u001b[39mrescale_factor, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format)\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    276\u001b[0m     ]\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/transformers/models/vit/image_processing_vit.py:268\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    264\u001b[0m     input_data_format \u001b[38;5;241m=\u001b[39m infer_channel_dimension_format(images[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_resize:\n\u001b[1;32m    267\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 268\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    270\u001b[0m     ]\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_rescale:\n\u001b[1;32m    273\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale(image\u001b[38;5;241m=\u001b[39mimage, scale\u001b[38;5;241m=\u001b[39mrescale_factor, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format)\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    276\u001b[0m     ]\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/transformers/models/vit/image_processing_vit.py:153\u001b[0m, in \u001b[0;36mViTImageProcessor.resize\u001b[0;34m(self, image, size, resample, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `size` dictionary must contain the keys `height` and `width`. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m output_size \u001b[38;5;241m=\u001b[39m (size[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m], size[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/transformers/image_transforms.py:330\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, size, resample, reducing_gap, data_format, return_numpy, input_data_format)\u001b[0m\n\u001b[1;32m    328\u001b[0m height, width \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# PIL images are in the format (width, height)\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m resized_image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreducing_gap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreducing_gap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_numpy:\n\u001b[1;32m    333\u001b[0m     resized_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(resized_image)\n",
            "File \u001b[0;32m~/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/PIL/Image.py:2200\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2192\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2193\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2194\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2195\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2196\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2197\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2198\u001b[0m         )\n\u001b[0;32m-> 2200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import XCLIPProcessor, XCLIPModel # трансформеры\n",
        "from transformers import TrainingArguments, Trainer # обучение трансформеров\n",
        "from sklearn.model_selection import KFold # кросс валидация\n",
        "# from lion_pytorch import Lion # оптимайзер\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid # КРАСИВОЕ отображение фоток\n",
        "from glob import glob\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"models/\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-4,\n",
        "    weight_decay=1e-4,\n",
        "    per_device_train_batch_size=128,\n",
        "    gradient_accumulation_steps=1,\n",
        "    per_device_eval_batch_size=128,\n",
        "    num_train_epochs=2,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=False,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    optim='adamw_torch',\n",
        "    save_total_limit=1,\n",
        "    \n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=ds[\"train\"],\n",
        "    eval_dataset=ds[\"test\"],\n",
        "    tokenizer=preprocessor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-14 10:35:06.312517: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-04-14 10:35:06.339436: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-14 10:35:06.339482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-14 10:35:06.340236: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-14 10:35:06.344548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-14 10:35:07.016314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            " * Serving Flask app 'main'\n",
            " * Debug mode: off\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [14/Apr/2024 10:35:11] \"GET / HTTP/1.1\" 200 -\n",
            "favicon.ico\n",
            "[]\n",
            "[2024-04-14 10:35:11,747] ERROR in app: Exception on /favicon.ico [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 1463, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 872, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 870, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 855, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
            "  File \"/home/misha/Documents/cp/main.py\", line 65, in check_file\n",
            "    path = f'train/{v1[0]}/{v1[1]}'\n",
            "IndexError: list index out of range\n",
            "127.0.0.1 - - [14/Apr/2024 10:35:11] \"\u001b[35m\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" 500 -\n",
            "24798084.jpg\n",
            "127.0.0.1 - - [14/Apr/2024 10:35:16] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
            "24798084.jpg\n",
            "[]\n",
            "[2024-04-14 10:35:16,464] ERROR in app: Exception on /24798084.jpg [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 1463, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 872, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 870, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 855, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
            "  File \"/home/misha/Documents/cp/main.py\", line 65, in check_file\n",
            "    path = f'train/{v1[0]}/{v1[1]}'\n",
            "IndexError: list index out of range\n",
            "127.0.0.1 - - [14/Apr/2024 10:35:16] \"\u001b[35m\u001b[1mGET /24798084.jpg HTTP/1.1\u001b[0m\" 500 -\n",
            "favicon.ico\n",
            "[]\n",
            "[2024-04-14 10:35:16,475] ERROR in app: Exception on /favicon.ico [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 1463, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 872, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 870, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/home/misha/Documents/DATA_FUSION2024_GEO_COMPANION-main/.conda/lib/python3.9/site-packages/flask/app.py\", line 855, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
            "  File \"/home/misha/Documents/cp/main.py\", line 65, in check_file\n",
            "    path = f'train/{v1[0]}/{v1[1]}'\n",
            "IndexError: list index out of range\n",
            "127.0.0.1 - - [14/Apr/2024 10:35:16] \"\u001b[35m\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" 500 -\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#!python main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model('swinv2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j0HUdKCFLvK"
      },
      "outputs": [],
      "source": [
        "new_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XwaLWvxFLvK"
      },
      "outputs": [],
      "source": [
        "probabilities = nn.functional.softmax(torch.tensor(new_predictions.predictions[0:10]), dim=-1)\n",
        "\n",
        "for i in range(0, 10):\n",
        "  array = ds['test'][i]['pixel_values'].numpy()\n",
        "\n",
        "  # Отображение изображений\n",
        "  fig, axes = plt.subplots(1, len(array), figsize=(10, 5))\n",
        "  for i in range(len(array)):\n",
        "      axes[i].imshow(array[i], cmap='gray')\n",
        "      axes[i].axis('off')\n",
        "  print(float(max(probabilities)), name_class[probabilities.argmax()])\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08549656f83e45e288ab91431e279f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19cdf0616e0f49a0949027f05eebc3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26a7b185e2384803b29871db20f894b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e293b426a0940fb9c33b33ba2d08e40",
            "max": 20345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c695e677533d4f48a77c1117afa7ecc6",
            "value": 20345
          }
        },
        "28e1f2a4ca0e45e7b8819e88ca7d69ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eed4f05915c49539c6c8aa3510436f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ee614194194f39ad8c94fe711a139a",
            "placeholder": "​",
            "style": "IPY_MODEL_c248d5dbcc944693a3b5f9dcf5ab06c6",
            "value": " 20345/20345 [00:00&lt;00:00, 271232.01 examples/s]"
          }
        },
        "619e5ec37fd040ff808d37bdc58abe9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f735b9a721d4e2a93ea9fa342ccb83d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77024ec0fa7d4078afe6a3f1498c480c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a05434793314355930f19a6a394c7b3",
            "placeholder": "​",
            "style": "IPY_MODEL_85b8869fde344cfbb77418ee6168e981",
            "value": "Casting to class labels: 100%"
          }
        },
        "85b8869fde344cfbb77418ee6168e981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a05434793314355930f19a6a394c7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc5e38c61034393ad64e0bb8cd828e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d7447ecbb140639f339d6f6fa3bb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab69d4930c24461ab6d52edb6fd4da4c",
              "IPY_MODEL_26a7b185e2384803b29871db20f894b9",
              "IPY_MODEL_5eed4f05915c49539c6c8aa3510436f4"
            ],
            "layout": "IPY_MODEL_619e5ec37fd040ff808d37bdc58abe9e"
          }
        },
        "9e293b426a0940fb9c33b33ba2d08e40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1ee614194194f39ad8c94fe711a139a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab69d4930c24461ab6d52edb6fd4da4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae586cb2e594ee59f495d0201fbee33",
            "placeholder": "​",
            "style": "IPY_MODEL_28e1f2a4ca0e45e7b8819e88ca7d69ae",
            "value": "Stringifying the column: 100%"
          }
        },
        "af63a2bdeadb406889a9a3f898e33eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c248d5dbcc944693a3b5f9dcf5ab06c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c695e677533d4f48a77c1117afa7ecc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cae586cb2e594ee59f495d0201fbee33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7f103ed4cd49d6a2f7ea884e3a098f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77024ec0fa7d4078afe6a3f1498c480c",
              "IPY_MODEL_fdd0f271705844f9bef09e6fcf27e0ab",
              "IPY_MODEL_f1bf1dbce5e94a6e86133141241a2669"
            ],
            "layout": "IPY_MODEL_8cc5e38c61034393ad64e0bb8cd828e5"
          }
        },
        "f1bf1dbce5e94a6e86133141241a2669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08549656f83e45e288ab91431e279f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_af63a2bdeadb406889a9a3f898e33eef",
            "value": " 20345/20345 [00:00&lt;00:00, 250260.62 examples/s]"
          }
        },
        "fdd0f271705844f9bef09e6fcf27e0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f735b9a721d4e2a93ea9fa342ccb83d",
            "max": 20345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19cdf0616e0f49a0949027f05eebc3de",
            "value": 20345
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
